{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839cb11b",
   "metadata": {},
   "source": [
    "# 04 Transformer Training\n",
    "\n",
    "В этом ноутбуке будет осуществлена тренировка нейросетевой архитектуры на основе трансформера (esm_classifier) для задачи предсказания вторичной структуры белка по аминокислотным последовательностям.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fc46db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x26bdd1e3230>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6eca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Загрузка предобработанных данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"/trinity/home/e.bulavko/a.khokhlov/data/processed\"\n",
    "\n",
    "Xtrain = np.load(f'{base_path}/X_train.npy')\n",
    "ytrain = np.load(f'{base_path}/y_train.npy')\n",
    "\n",
    "Xval = np.load(f'{base_path}/X_val.npy')\n",
    "yval = np.load(f'{base_path}/y_val.npy')\n",
    "\n",
    "Xtest = np.load(f'{base_path}/X_test.npy')\n",
    "ytest = np.load(f'{base_path}/y_test.npy')\n",
    "\n",
    "mask_train = np.load(f'{base_path}/mask_train.npy')\n",
    "mask_val = np.load(f'{base_path}/mask_val.npy')\n",
    "mask_test = np.load(f'{base_path}/mask_test.npy')\n",
    "\n",
    "class_weights = np.load(f'{base_path}/class_weights.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Кастомный Dataset для PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11c674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, X, y, mask):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input': torch.LongTensor(self.X[idx]),\n",
    "            'target': torch.LongTensor(self.y[idx]),\n",
    "            'mask': torch.BoolTensor(self.mask[idx]),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7653341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA DIAGNOSTICS ===\n",
      "1. Shapes: X=(381769, 700), y=(381769, 700), mask=(381769, 700)\n",
      "2. Value ranges:\n",
      "   X: min=0, max=20, expected=[0, 21)\n",
      "   y: min=0, max=3, expected=[0, 4)\n",
      "   mask: min=0, max=1, expected=[0, 1]\n",
      "3. Data types: X=int64, y=int64, mask=int64\n",
      "4. Valid positions per sequence: min=0, max=700\n",
      "   WARNING: Some sequences are ALL padding!\n",
      "Sequences with ALL padding: 1142 / 381769 (0.30%)\n",
      "WARNING: These sequences should be REMOVED or handled specially!\n",
      "5. Class distribution (only valid positions):\n",
      "   Class 1: 33488580 (34.0%)\n",
      "   Class 2: 20365789 (20.7%)\n",
      "   Class 3: 44653636 (45.3%)\n",
      "=== ALL CHECKS PASSED ===\n",
      "=== DATA DIAGNOSTICS ===\n",
      "1. Shapes: X=(47668, 700), y=(47668, 700), mask=(47668, 700)\n",
      "2. Value ranges:\n",
      "   X: min=0, max=20, expected=[0, 21)\n",
      "   y: min=0, max=3, expected=[0, 4)\n",
      "   mask: min=0, max=1, expected=[0, 1]\n",
      "3. Data types: X=int64, y=int64, mask=int64\n",
      "4. Valid positions per sequence: min=0, max=700\n",
      "   WARNING: Some sequences are ALL padding!\n",
      "Sequences with ALL padding: 153 / 47668 (0.32%)\n",
      "WARNING: These sequences should be REMOVED or handled specially!\n",
      "5. Class distribution (only valid positions):\n",
      "   Class 1: 4185893 (33.9%)\n",
      "   Class 2: 2563599 (20.8%)\n",
      "   Class 3: 5591449 (45.3%)\n",
      "=== ALL CHECKS PASSED ===\n",
      "=== DATA DIAGNOSTICS ===\n",
      "1. Shapes: X=(47716, 700), y=(47716, 700), mask=(47716, 700)\n",
      "2. Value ranges:\n",
      "   X: min=0, max=20, expected=[0, 21)\n",
      "   y: min=0, max=3, expected=[0, 4)\n",
      "   mask: min=0, max=1, expected=[0, 1]\n",
      "3. Data types: X=int64, y=int64, mask=int64\n",
      "4. Valid positions per sequence: min=0, max=700\n",
      "   WARNING: Some sequences are ALL padding!\n",
      "Sequences with ALL padding: 141 / 47716 (0.30%)\n",
      "WARNING: These sequences should be REMOVED or handled specially!\n",
      "5. Class distribution (only valid positions):\n",
      "   Class 1: 4191683 (34.0%)\n",
      "   Class 2: 2544756 (20.7%)\n",
      "   Class 3: 5582646 (45.3%)\n",
      "=== ALL CHECKS PASSED ===\n"
     ]
    }
   ],
   "source": [
    "def diagnose_data(X, y, mask, vocab_size=21, num_labels=4):\n",
    "    \"\"\"Проверяет корректность данных\"\"\"\n",
    "    \n",
    "    print(\"=== DATA DIAGNOSTICS ===\")\n",
    "    \n",
    "    # 1. Формы\n",
    "    print(f\"1. Shapes: X={X.shape}, y={y.shape}, mask={mask.shape}\")\n",
    "    assert X.shape == y.shape == mask.shape, \"Shape mismatch!\"\n",
    "    \n",
    "    # 2. Диапазоны\n",
    "    print(f\"2. Value ranges:\")\n",
    "    print(f\"   X: min={X.min()}, max={X.max()}, expected=[0, {vocab_size})\")\n",
    "    print(f\"   y: min={y.min()}, max={y.max()}, expected=[0, {num_labels})\")\n",
    "    print(f\"   mask: min={mask.min()}, max={mask.max()}, expected=[0, 1]\")\n",
    "    \n",
    "    assert X.min() >= 0 and X.max() < vocab_size, \"X out of range!\"\n",
    "    assert y.min() >= 0 and y.max() < num_labels, \"y out of range!\"\n",
    "    assert set(np.unique(mask)) <= {0, 1}, \"mask not binary!\"\n",
    "    \n",
    "    # 3. Типы данных\n",
    "    print(f\"3. Data types: X={X.dtype}, y={y.dtype}, mask={mask.dtype}\")\n",
    "    \n",
    "    # 4. Маски не все нули\n",
    "    mask_per_seq = mask.sum(axis=1)\n",
    "    print(f\"4. Valid positions per sequence: min={mask_per_seq.min()}, max={mask_per_seq.max()}\")\n",
    "    \n",
    "    if (mask_per_seq == 0).any():\n",
    "        print(\"   WARNING: Some sequences are ALL padding!\")\n",
    "    all_padding = (mask.sum(axis=1) == 0).sum()\n",
    "    print(f\"Sequences with ALL padding: {all_padding} / {len(mask)} ({100*all_padding/len(mask):.2f}%)\")\n",
    "\n",
    "    if all_padding > 0:\n",
    "        print(\"WARNING: These sequences should be REMOVED or handled specially!\")\n",
    "    \n",
    "    # 5. Распределение классов\n",
    "    y_valid = y[mask == 1]\n",
    "    if len(y_valid) > 0:\n",
    "        unique, counts = np.unique(y_valid, return_counts=True)\n",
    "        print(f\"5. Class distribution (only valid positions):\")\n",
    "        for cls, cnt in zip(unique, counts):\n",
    "            print(f\"   Class {cls}: {cnt} ({100*cnt/len(y_valid):.1f}%)\")\n",
    "    \n",
    "    print(\"=== ALL CHECKS PASSED ===\")\n",
    "\n",
    "# Использование:\n",
    "diagnose_data(Xtrain, ytrain, mask_train)\n",
    "diagnose_data(Xval, yval, mask_val)\n",
    "diagnose_data(Xtest, ytest, mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d2a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FILTERING ALL-PADDING SEQUENCES ===\n",
      "Removing 1142 all-padding sequences\n",
      "Removing 153 all-padding sequences\n",
      "Removing 141 all-padding sequences\n",
      "Train: 380627 sequences\n",
      "Val: 47515 sequences\n",
      "Test: 47575 sequences\n"
     ]
    }
   ],
   "source": [
    "def remove_all_padding_sequences(X, y, mask):\n",
    "    \"\"\"Удаляет последовательности, которые целиком padding\"\"\"\n",
    "    # Вычисляем количество валидных позиций в каждой последовательности\n",
    "    valid_count = mask.sum(axis=1)\n",
    "    \n",
    "    # Оставляем только последовательности с хотя бы одной валидной позицией\n",
    "    valid_idx = valid_count > 0\n",
    "    \n",
    "    n_removed = (~valid_idx).sum()\n",
    "    print(f\"Removing {n_removed} all-padding sequences\")\n",
    "    \n",
    "    return X[valid_idx], y[valid_idx], mask[valid_idx]\n",
    "\n",
    "# Применяем фильтр ко всем наборам\n",
    "print(\"\\n=== FILTERING ALL-PADDING SEQUENCES ===\")\n",
    "\n",
    "Xtrain, ytrain, mask_train = remove_all_padding_sequences(Xtrain, ytrain, mask_train)\n",
    "Xval, yval, mask_val = remove_all_padding_sequences(Xval, yval, mask_val)\n",
    "Xtest, ytest, mask_test = remove_all_padding_sequences(Xtest, ytest, mask_test)\n",
    "\n",
    "print(f\"Train: {Xtrain.shape[0]} sequences\")\n",
    "print(f\"Val: {Xval.shape[0]} sequences\")\n",
    "print(f\"Test: {Xtest.shape[0]} sequences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642fb247",
   "metadata": {},
   "source": [
    "## DataLoader'ы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_dataset = ProteinDataset(Xtrain, ytrain, mask_train)\n",
    "val_dataset = ProteinDataset(Xval, yval, mask_val)\n",
    "test_dataset = ProteinDataset(Xtest, ytest, mask_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c48ee",
   "metadata": {},
   "source": [
    "## Определение архитектуры трансформера (esm_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f7b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_labels, d_model=128, nhead=8, num_layers=2, dim_feedforward=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=0)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='relu'\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model, num_labels)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        key_padding_mask = ~mask\n",
    "        x = self.transformer(x, src_key_padding_mask=key_padding_mask)\n",
    "        x = x.transpose(0, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7671d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Подготовка к обучению: функция потерь, модель, оптимизатор\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfee45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_labels = 4\n",
    "vocab_size = 21\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ESMClassifier(vocab_size, num_labels).to(device)\n",
    "weights = np.concatenate(([0.0], class_weights))\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32, device=device), ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4b7609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Цикл обучения с валидацией\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab53aab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 4 classes or no classes but got weight tensor of shape: [5]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m outputs = outputs.view(-\u001b[32m1\u001b[39m, num_labels)\n\u001b[32m     13\u001b[39m targets_flat = targets.view(-\u001b[32m1\u001b[39m).long()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m loss = \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss.backward()\n\u001b[32m     16\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1385\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1385\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\nn\\functional.py:3458\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3457\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: weight tensor should be defined either for all 4 classes or no classes but got weight tensor of shape: [5]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model.train()\n",
    "start = time.time()\n",
    "for i, batch in enumerate(train_loader):\n",
    "    inputs = batch['input'].to(device)\n",
    "    targets = batch['target'].to(device)\n",
    "    mask = batch['mask'].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs, mask)\n",
    "    outputs = outputs.view(-1, num_labels)\n",
    "    targets_flat = targets.view(-1).long()\n",
    "    loss = loss_fn(outputs, targets_flat)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i == 0:  # только одна итерация для оценки времени\n",
    "        break\n",
    "end = time.time()\n",
    "print(f\"Время обработки одного батча: {end - start:.2f} секунд\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd494e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(Xtrain)))\n",
    "print(np.any(np.isnan(ytrain)))\n",
    "print(np.any(np.isnan(mask_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb3b68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m targets_flat = targets.view(-\u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m loss = loss_fn(outputs, targets_flat)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "best_val_f1 = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['input'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, mask)\n",
    "        outputs = outputs.view(-1, num_labels)\n",
    "        targets_flat = targets.view(-1)\n",
    "        loss = loss_fn(outputs, targets_flat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch['input'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "            outputs = model(inputs, mask)\n",
    "            preds = outputs.argmax(dim=-1)\n",
    "            for i in range(inputs.size(0)):\n",
    "                seq_mask = mask[i].cpu().numpy()\n",
    "                all_preds.extend(preds[i][seq_mask].cpu().numpy())\n",
    "                all_targets.extend(targets[i][seq_mask].cpu().numpy())\n",
    "    if mask.sum() == 0: print('zero mask') \n",
    "    print(f'Epoch {epoch+1}, Train loss: {train_loss:.4f}')\n",
    "    print(classification_report(all_targets, all_preds, digits=3))\n",
    "\n",
    "    f1 = classification_report(all_targets, all_preds, output_dict=True, zero_division=0)['weighted avg']['f1-score']\n",
    "    if f1 > best_val_f1:\n",
    "        best_val_f1 = f1\n",
    "        torch.save(model.state_dict(), 'best_esm_classifier.pth')\n",
    "        print('Model saved!')\n",
    "\n",
    "print('Best validation F1:', best_val_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0df41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Тестирование лучшей модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c4507",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_esm_classifier.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest_esm_classifier.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m model.eval()\n\u001b[32m      3\u001b[39m all_test_preds = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'best_esm_classifier.pth'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_esm_classifier.pth'))\n",
    "model.eval()\n",
    "all_test_preds = []\n",
    "all_test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['input'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        outputs = model(inputs, mask)\n",
    "        preds = outputs.argmax(dim=-1)\n",
    "        for i in range(inputs.size(0)):\n",
    "            seq_mask = mask[i].cpu().numpy()\n",
    "            all_test_preds.extend(preds[i][seq_mask].cpu().numpy())\n",
    "            all_test_targets.extend(targets[i][seq_mask].cpu().numpy())\n",
    "\n",
    "print(classification_report(all_test_targets, all_test_preds, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8310e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
