{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caef7ad4",
   "metadata": {},
   "source": [
    "# Ноутбук 02: Data Preprocessing\n",
    "\n",
    "**Цель:**\n",
    "\n",
    "- Подготовить данные для обучения моделей;\n",
    "\n",
    "- Закодировать последовательности в числа;\n",
    "\n",
    "- Применить padding;\n",
    "\n",
    "- Разделить на train/val/test;\n",
    "\n",
    "- Сохранить результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97a805",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35a9373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/2022-08-03-ss.cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b2f29",
   "metadata": {},
   "source": [
    "## Создание словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefabe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Словарь aa_to_int: {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20, '<PAD>': 0}\n",
      "\n",
      "Словарь ss_to_int: {'H': 1, 'E': 2, 'C': 3, '<PAD>': 0}\n"
     ]
    }
   ],
   "source": [
    "AMINO_ACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "aa_to_int = {aa: i+1 for i, aa in enumerate(AMINO_ACIDS)}\n",
    "aa_to_int['<PAD>'] = 0\n",
    "int_to_aa = {v: k for k, v in aa_to_int.items()}\n",
    "\n",
    "\n",
    "STRUCTURES = 'HEC'\n",
    "ss_to_int = {ss: i+1 for i, ss in enumerate(STRUCTURES)}\n",
    "ss_to_int['<PAD>'] = 0\n",
    "int_to_ss = {v: k for k, v in ss_to_int.items()}\n",
    "\n",
    "\n",
    "print(f\"\\nСловарь aa_to_int: {aa_to_int}\")\n",
    "print(f\"\\nСловарь ss_to_int: {ss_to_int}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976751c6",
   "metadata": {},
   "source": [
    "## Функции кодирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf237e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq, vocab):\n",
    "    \"\"\"Кодирует строку в список чисел\"\"\"\n",
    "    return [vocab.get(char, 0) for char in seq]\n",
    "\n",
    "def decode_sequence(encoded, vocab_reverse):\n",
    "    \"\"\"Декодирует числа обратно в строку\"\"\"\n",
    "    return ''.join([vocab_reverse.get(i, '<PAD>') for i in encoded])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493bf18",
   "metadata": {},
   "source": [
    "## Padding функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d93b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_length, pad_value=0):\n",
    "    \"\"\"Применяет padding или truncation\"\"\"\n",
    "    if len(seq) > max_length:\n",
    "        # Обрезаем\n",
    "        return np.array(seq[:max_length])\n",
    "    else:\n",
    "        # Дополняем нулями\n",
    "        padded = np.zeros(max_length, dtype=int)\n",
    "        padded[:len(seq)] = seq\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afdfb51",
   "metadata": {},
   "source": [
    "##  Выбор max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56d312a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length=700 покрывает 96.48% данных\n",
      "Будет обрезано 16798 последовательностей\n"
     ]
    }
   ],
   "source": [
    "max_length = 700\n",
    "\n",
    "\n",
    "coverage = (df['len'] <= max_length).sum() / len(df) * 100\n",
    "print(f\"max_length={max_length} покрывает {coverage:.2f}% данных\")\n",
    "print(f\"Будет обрезано {len(df[df['len'] > max_length])} последовательностей\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6e868",
   "metadata": {},
   "source": [
    "## Обработка всего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2b53a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма X (последовательности): (477153, 700)\n",
      "Форма y (структуры): (477153, 700)\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # Кодируем последовательность\n",
    "    seq_encoded = encode_sequence(row['seq'], aa_to_int)\n",
    "    seq_padded = pad_sequence(seq_encoded, max_length)\n",
    "    \n",
    "    # Кодируем структуру\n",
    "    struct_encoded = encode_sequence(row['sst3'], ss_to_int)\n",
    "    struct_padded = pad_sequence(struct_encoded, max_length)\n",
    "    \n",
    "    X_list.append(seq_padded)\n",
    "    y_list.append(struct_padded)\n",
    "\n",
    "\n",
    "X = np.array(X_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(f\"Форма X (последовательности): {X.shape}\")\n",
    "print(f\"Форма y (структуры): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b7738",
   "metadata": {},
   "source": [
    "## Разделение на train/val/test с учётом дисбаланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9eb1ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dominant_class'] = df['sst3'].apply(\n",
    "    lambda s: max(['H', 'E', 'C'], key=lambda c: s.count(c))\n",
    ")\n",
    "\n",
    "# Stratified split\n",
    "dominant_classes = df['dominant_class'].values\n",
    "\n",
    "X_temp, X_test, y_temp, y_test, _, _ = train_test_split(\n",
    "    X, y, dominant_classes,\n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    stratify=dominant_classes\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val, _, _ = train_test_split(\n",
    "    X_temp, y_temp, dominant_classes[:len(X_temp)],\n",
    "    test_size=0.111,\n",
    "    random_state=42,\n",
    "    stratify=dominant_classes[:len(X_temp)]\n",
    ")\n",
    "\n",
    "# Вычисляем class weights\n",
    "all_labels = y_train[y_train != 0]\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.array([1, 2, 3]),\n",
    "    y=all_labels\n",
    ")\n",
    "\n",
    "# Сохраняем всё\n",
    "np.save('../data/processed/class_weights.npy', class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "751bf8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Весь датасет:\n",
      "  H: 152988 (32.1%)\n",
      "  E: 44311 (9.3%)\n",
      "  C: 279854 (58.7%)\n",
      "\n",
      "Train:\n",
      "  H: 122406 (32.1%)\n",
      "  E: 35453 (9.3%)\n",
      "  C: 223910 (58.7%)\n",
      "\n",
      "Val:\n",
      "  H: 15283 (32.1%)\n",
      "  E: 4427 (9.3%)\n",
      "  C: 27958 (58.7%)\n",
      "\n",
      "Test:\n",
      "  H: 15299 (32.1%)\n",
      "  E: 4431 (9.3%)\n",
      "  C: 27986 (58.7%)\n"
     ]
    }
   ],
   "source": [
    "def check_distribution(classes, name):\n",
    "    counts = Counter(classes)\n",
    "    total = len(classes)\n",
    "    print(f\"\\n{name}:\")\n",
    "    for cls in ['H', 'E', 'C']:\n",
    "        print(f\"  {cls}: {counts[cls]} ({counts[cls]/total*100:.1f}%)\")\n",
    "\n",
    "check_distribution(dominant_classes, \"Весь датасет\")\n",
    "check_distribution(classes_train, \"Train\")\n",
    "check_distribution(classes_val, \"Val\")\n",
    "check_distribution(classes_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d71cad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weights:\n",
      "  H (1): 0.980\n",
      "  E (2): 1.614\n",
      "  C (3): 0.735\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nClass weights:\")\n",
    "print(f\"  H (1): {class_weights[0]:.3f}\")\n",
    "print(f\"  E (2): {class_weights[1]:.3f}\")\n",
    "print(f\"  C (3): {class_weights[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7602bf",
   "metadata": {},
   "source": [
    "## Создание масок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16febcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма mask_train: (381769, 700)\n"
     ]
    }
   ],
   "source": [
    "def create_mask(sequences):\n",
    "    \"\"\"Создаёт маску: 1 для валидных позиций, 0 для padding\"\"\"\n",
    "    return (sequences != 0).astype(int)\n",
    "\n",
    "# Создаём маски для всех наборов\n",
    "mask_train = create_mask(X_train)\n",
    "mask_val = create_mask(X_val)\n",
    "mask_test = create_mask(X_test)\n",
    "\n",
    "print(f\"Форма mask_train: {mask_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91334040",
   "metadata": {},
   "source": [
    "## Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02813f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Все данные сохранены в data/processed/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Создаём папку если не существует\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Сохраняем массивы\n",
    "np.save('../data/processed/X_train.npy', X_train)\n",
    "np.save('../data/processed/y_train.npy', y_train)\n",
    "np.save('../data/processed/X_val.npy', X_val)\n",
    "np.save('../data/processed/y_val.npy', y_val)\n",
    "np.save('../data/processed/X_test.npy', X_test)\n",
    "np.save('../data/processed/y_test.npy', y_test)\n",
    "\n",
    "# Сохраняем маски\n",
    "np.save('../data/processed/mask_train.npy', mask_train)\n",
    "np.save('../data/processed/mask_val.npy', mask_val)\n",
    "np.save('../data/processed/mask_test.npy', mask_test)\n",
    "\n",
    "# Сохраняем словари\n",
    "vocabularies = {\n",
    "    'aa_to_int': aa_to_int,\n",
    "    'int_to_aa': int_to_aa,\n",
    "    'ss_to_int': ss_to_int,\n",
    "    'int_to_ss': int_to_ss,\n",
    "    'max_length': max_length\n",
    "}\n",
    "\n",
    "with open('../data/processed/vocabularies.pkl', 'wb') as f:\n",
    "    pickle.dump(vocabularies, f)\n",
    "\n",
    "print(\"Все данные сохранены в data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab66bcc",
   "metadata": {},
   "source": [
    "## Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43239db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train загружен: (381769, 700)\n",
      "\n",
      "Пример 1\n",
      "Длина: 257\n",
      "Sequence: MLSAFQLENNRLTRLEVEESQPLVNAVWIDLVEPDDDERLRVQSELGQSLATRPELEDIE...\n",
      "Structure: CEEEEEECCCCEEECCCCCCCCCCCCCEEEEECCCHHHHHHHHHHCCCCCCCHHHHCCCC...\n",
      "Encoded X (первые 10): [11 10 16  1  5 14 10  4 12 12]\n",
      "Encoded y (первые 10): [3 2 2 2 2 2 2 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Проверяем что можем загрузить\n",
    "X_train_loaded = np.load('../data/processed/X_train.npy')\n",
    "print(f\"X_train загружен: {X_train_loaded.shape}\")\n",
    "\n",
    "for i in range(1):\n",
    "    print(f\"\\nПример {i+1}\")\n",
    "    \n",
    "    # Декодируем обратно\n",
    "    seq_decoded = decode_sequence(X_train[i], int_to_aa)\n",
    "    struct_decoded = decode_sequence(y_train[i], int_to_ss)\n",
    "    \n",
    "    # Убираем padding\n",
    "    length = mask_train[i].sum()\n",
    "    seq_clean = seq_decoded[:length]\n",
    "    struct_clean = struct_decoded[:length]\n",
    "    \n",
    "    print(f\"Длина: {length}\")\n",
    "    print(f\"Sequence: {seq_clean[:60]}...\")\n",
    "    print(f\"Structure: {struct_clean[:60]}...\")\n",
    "    print(f\"Encoded X (первые 10): {X_train[i][:10]}\")\n",
    "    print(f\"Encoded y (первые 10): {y_train[i][:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e36c01",
   "metadata": {},
   "source": [
    "# Выводы:\n",
    "\n",
    "### 1. Размеры обработанных данных\n",
    "\n",
    "**Успешно подготовлено:**\n",
    "- **Train:** 381,769 белков (80%)\n",
    "- **Validation:** 47,668 белков (10%)\n",
    "- **Test:** 47,716 белков (10%)\n",
    "- **Всего:** 477,153 белковых последовательности\n",
    "\n",
    "**Форма данных:**\n",
    "- `X` (последовательности): (N, 700) — закодированные аминокислоты\n",
    "- `y` (структуры): (N, 700) — закодированные метки H/E/C\n",
    "- `mask` (маски): (N, 700) — индикаторы валидных позиций\n",
    "\n",
    "***\n",
    "\n",
    "### 2. Параметры кодирования\n",
    "\n",
    "**Словари:**\n",
    "- **Аминокислоты:** 21 токен (20 стандартных + padding)\n",
    "  - A→1, C→2, D→3, ..., Y→20, `<PAD>`→0\n",
    "- **Структуры:** 4 класса\n",
    "  - H (Helix)→1, E (Sheet)→2, C (Coil)→3, `<PAD>`→0\n",
    "\n",
    "**Параметры padding:**\n",
    "- `max_length = 700` — покрывает **96.48%** данных\n",
    "- Обрезано: 16,798 последовательностей (3.52%) длиннее 700 аминокислот\n",
    "- **Обоснование:** баланс между сохранением данных и эффективностью обучения\n",
    "\n",
    "***\n",
    "\n",
    "### 3. Распределение классов (Stratified Split)\n",
    "\n",
    "**Применена стратификация по доминирующему классу каждого белка:**\n",
    "\n",
    "| Набор | H (Helix) | E (Sheet) | C (Coil) |\n",
    "|-------|-----------|-----------|----------|\n",
    "| **Весь датасет** | 32.1% | 9.3% | 58.7% |\n",
    "| **Train** | 32.1% | 9.3% | 58.7% |\n",
    "| **Val** | 32.1% | 9.3% | 58.7% |\n",
    "| **Test** | 32.1% | 9.3% | 58.7% |\n",
    "\n",
    "**Пропорции классов сохранены во всех наборах!**\n",
    "\n",
    "***\n",
    "\n",
    "### 4. Class Weights для борьбы с дисбалансом\n",
    "\n",
    "**Вычислены веса для weighted loss:**\n",
    "- **H (1):** 0.980 — почти нейтральный вес\n",
    "- **E (2):** 1.614 — **повышенный** вес (редкий класс, 9.3%)\n",
    "- **C (3):** 0.735 — пониженный вес (частый класс, 58.7%)\n",
    "\n",
    "**Назначение:** \n",
    "При обучении модель будет **больше штрафоваться** за ошибки на редком классе E (Sheet) и меньше на частом классе C (Coil). Это компенсирует дисбаланс классов.\n",
    "\n",
    "**Сохранено:** `../data/processed/class_weights.npy`\n",
    "\n",
    "***\n",
    "\n",
    "### 5. Маски для игнорирования padding\n",
    "\n",
    "**Созданы маски для всех наборов:**\n",
    "- `mask[i, j] = 1` — валидная позиция (реальная аминокислота)\n",
    "- `mask[i, j] = 0` — padding (дополнение нулями)\n",
    "\n",
    "**Пример использования при обучении:**\n",
    "```python\n",
    "# Loss будет вычисляться только на валидных позициях\n",
    "loss = criterion(predictions, targets)  # ignore_index=0 автоматически игнорирует padding\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### 6. Проверка корректности\n",
    "\n",
    "**Тестирование encoding/decoding:**\n",
    "- ✅ Последовательности корректно кодируются в числа\n",
    "- ✅ Декодирование восстанавливает исходные строки (без padding)\n",
    "- ✅ Маски правильно определяют границы реальных данных\n",
    "\n",
    "**Пример:**\n",
    "```\n",
    "Оригинал:  \"MLSAFQLENNRL...\"\n",
    "Encoded:   [11, 10, 16, 1, 5, 14, ...]\n",
    "Decoded:   \"MLSAFQLENNRL...\"  ✅ Совпадает\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### 7. Сохранённые файлы\n",
    "\n",
    "**Все данные сохранены в `../data/processed/`:**\n",
    "\n",
    "```\n",
    "data/processed/\n",
    "├── X_train.npy          # Тренировочные последовательности\n",
    "├── y_train.npy          # Тренировочные структуры\n",
    "├── X_val.npy            # Валидационные последовательности\n",
    "├── y_val.npy            # Валидационные структуры\n",
    "├── X_test.npy           # Тестовые последовательности\n",
    "├── y_test.npy           # Тестовые структуры\n",
    "├── mask_train.npy       # Маски для train\n",
    "├── mask_val.npy         # Маски для val\n",
    "├── mask_test.npy        # Маски для test\n",
    "├── class_weights.npy    # Веса классов для weighted loss\n",
    "└── vocabularies.pkl     # Словари и параметры (max_length, aa_to_int, etc.)\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### 8. Ключевые решения и обоснования\n",
    "\n",
    "| Решение | Обоснование |\n",
    "|---------|-------------|\n",
    "| **max_length=700** | Покрывает 96.5% данных, оптимальный баланс |\n",
    "| **Stratified split** | Сохраняет пропорции классов H/E/C во всех наборах |\n",
    "| **Class weights** | Компенсирует дисбаланс: E (9.3%) получает вес 1.614 |\n",
    "| **Padding token=0** | Стандартная практика, позволяет игнорировать при loss |\n",
    "| **80/10/10 split** | Достаточно данных для обучения и надёжной оценки |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
